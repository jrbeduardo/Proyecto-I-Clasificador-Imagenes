{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a8faec",
   "metadata": {},
   "source": [
    "## ¿Qué es una CNN?\n",
    "\n",
    "Las CNNs son redes neuronales especialmente diseñadas para procesar datos con estructura de cuadrícula, como imágenes. Su arquitectura está inspirada en el sistema visual biológico y utiliza tres operaciones principales:\n",
    "\n",
    "### 1. Convolución\n",
    "Aplica filtros (kernels) que detectan características locales como bordes, texturas y patrones.\n",
    "\n",
    "$$\n",
    "(f * g)(x, y) = \\sum_{i=-k}^{k} \\sum_{j=-k}^{k} f(i, j) \\cdot g(x-i, y-j)\n",
    "$$\n",
    "\n",
    "### 2. Pooling\n",
    "Reduce la dimensionalidad espacial, conservando las características más importantes (max pooling, average pooling).\n",
    "\n",
    "### 3. Capas Completamente Conectadas\n",
    "Al final de la red, realizan la clasificación basándose en las características extraídas.\n",
    "\n",
    "## Ventajas de las CNNs\n",
    "\n",
    "- **Invarianza espacial**: Detectan características sin importar su posición en la imagen\n",
    "- **Compartición de parámetros**: Los mismos filtros se aplican en toda la imagen\n",
    "- **Jerarquía de características**: Capas iniciales detectan bordes, capas intermedias formas, capas finales objetos completos\n",
    "- **Eficiencia**: Menos parámetros que redes completamente conectadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922533b",
   "metadata": {},
   "source": [
    "## Implementación: CNN para Clasificación MNIST\n",
    "\n",
    "Construiremos una CNN simple para clasificar dígitos manuscritos del dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b90101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Usando dispositivo: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e1317",
   "metadata": {},
   "source": [
    "### Arquitectura de la CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc8dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Primera capa convolucional: 1 canal de entrada (escala de grises) -> 32 canales\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 28x28 -> 14x14\n",
    "        \n",
    "        # Segunda capa convolucional: 32 canales -> 64 canales\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 14x14 -> 7x7\n",
    "        \n",
    "        # Capas completamente conectadas\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 clases (dígitos 0-9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Bloque convolucional 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Bloque convolucional 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Aplanar para capas densas\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        \n",
    "        # Capas completamente conectadas\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Crear modelo\n",
    "model = SimpleCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9328e6a7",
   "metadata": {},
   "source": [
    "### Preparar Dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones: convertir a tensor y normalizar\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Media y desviación estándar de MNIST\n",
    "])\n",
    "\n",
    "# Descargar y cargar datos\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "print(f'Tamaño del conjunto de entrenamiento: {len(train_dataset)}')\n",
    "print(f'Tamaño del conjunto de prueba: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15bf6c5",
   "metadata": {},
   "source": [
    "### Visualizar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c182826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar algunas imágenes de ejemplo\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(example_data[i][0], cmap='gray')\n",
    "    ax.set_title(f'Etiqueta: {example_targets[i]}')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b90148",
   "metadata": {},
   "source": [
    "### Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a972857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train_epoch(model, device, train_loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss, accuracy\n",
    "\n",
    "# Función de evaluación\n",
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88c9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "epochs = 5\n",
    "train_losses, test_losses = [], []\n",
    "train_accs, test_accs = [], []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train_epoch(model, device, train_loader, optimizer, criterion)\n",
    "    test_loss, test_acc = test(model, device, test_loader, criterion)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    print(f'Época {epoch}/{epochs}')\n",
    "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed445e4",
   "metadata": {},
   "source": [
    "### Visualizar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficas de pérdida y precisión\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1.plot(range(1, epochs+1), train_losses, label='Train Loss', marker='o')\n",
    "ax1.plot(range(1, epochs+1), test_losses, label='Test Loss', marker='s')\n",
    "ax1.set_xlabel('Época')\n",
    "ax1.set_ylabel('Pérdida')\n",
    "ax1.set_title('Pérdida durante el Entrenamiento')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(range(1, epochs+1), train_accs, label='Train Accuracy', marker='o')\n",
    "ax2.plot(range(1, epochs+1), test_accs, label='Test Accuracy', marker='s')\n",
    "ax2.set_xlabel('Época')\n",
    "ax2.set_ylabel('Precisión (%)')\n",
    "ax2.set_title('Precisión durante el Entrenamiento')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c65b0",
   "metadata": {},
   "source": [
    "### Predicciones en Nuevas Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342deab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones en un batch de prueba\n",
    "model.eval()\n",
    "test_examples = enumerate(test_loader)\n",
    "batch_idx, (test_data, test_targets) = next(test_examples)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_data = test_data.to(device)\n",
    "    output = model(test_data)\n",
    "    predictions = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "# Visualizar predicciones\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(test_data[i][0].cpu(), cmap='gray')\n",
    "    pred = predictions[i].item()\n",
    "    true = test_targets[i].item()\n",
    "    color = 'green' if pred == true else 'red'\n",
    "    ax.set_title(f'Pred: {pred} | Real: {true}', color=color)\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe6c9e6",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Esta CNN simple logra alta precisión en MNIST (~98-99%) con solo 5 épocas de entrenamiento. Las CNNs son extremadamente efectivas para tareas de visión porque:\n",
    "\n",
    "1. Aprenden jerarquías de características automáticamente\n",
    "2. Son invariantes a traslaciones\n",
    "3. Requieren menos parámetros que redes densas\n",
    "4. Generalizan bien a datos no vistos\n",
    "\n",
    "**Arquitecturas modernas** como ResNet, VGG, EfficientNet extienden estos principios con técnicas avanzadas:\n",
    "- Conexiones residuales (skip connections)\n",
    "- Batch normalization\n",
    "- Arquitecturas más profundas\n",
    "- Bloques de atención"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
