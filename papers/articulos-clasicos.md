# Artículos Clásicos de Redes Neuronales

Esta lista contiene artículos fundamentales que sentaron las bases del desarrollo de las redes neuronales y el aprendizaje profundo.

---

## 1. **The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain**

**Autor:** Frank Rosenblatt  
**Año:** 1958  
**Revista:** Psychological Review, Vol. 65, No. 6

**Resumen:** Artículo pionero que introduce el perceptrón, el primer modelo computacional de una neurona artificial. Establece los fundamentos del aprendizaje automático supervisado y la clasificación binaria.

**Importancia:** Marca el nacimiento de las redes neuronales artificiales y el aprendizaje automático.

---

## 2. **Learning Representations by Back-Propagating Errors**

**Autores:** David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams  
**Año:** 1986  
**Revista:** Nature, Vol. 323

**Resumen:** Presenta el algoritmo de retropropagación (backpropagation), que permite entrenar redes neuronales multicapa mediante el cálculo eficiente de gradientes.

**Importancia:** Revolucionó el entrenamiento de redes neuronales profundas, siendo la base del deep learning moderno.

---

## 3. **Gradient-Based Learning Applied to Document Recognition**

**Autores:** Yann LeCun, Léon Bottou, Yoshua Bengio, Patrick Haffner  
**Año:** 1998  
**Revista:** Proceedings of the IEEE, Vol. 86, No. 11

**Resumen:** Introduce LeNet-5, una arquitectura CNN exitosa para reconocimiento de dígitos manuscritos. Demuestra la efectividad de las convoluciones para procesamiento de imágenes.

**Importancia:** Estableció las bases arquitecturales de las CNNs modernas y su aplicación en visión por computadora.

---

## 4. **ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)**

**Autores:** Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton  
**Año:** 2012  
**Conferencia:** NeurIPS (Neural Information Processing Systems)

**Resumen:** Presenta AlexNet, que ganó la competencia ImageNet 2012 con un margen significativo usando una CNN profunda. Popularizó el uso de GPUs para entrenamiento y técnicas como ReLU y Dropout.

**Importancia:** Marcó el inicio de la era del deep learning y demostró el potencial de las redes profundas en tareas complejas.

---

## 5. **Deep Residual Learning for Image Recognition (ResNet)**

**Autores:** Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun  
**Año:** 2015  
**Conferencia:** CVPR (Conference on Computer Vision and Pattern Recognition)

**Resumen:** Introduce las conexiones residuales (skip connections) que permiten entrenar redes extremadamente profundas (hasta 152 capas) sin degradación del rendimiento.

**Importancia:** Resolvió el problema de la degradación en redes muy profundas y sigue siendo una arquitectura fundamental en visión por computadora.

---

## Recursos Adicionales

Para acceder a estos artículos:
- [Google Scholar](https://scholar.google.com/)
- [arXiv.org](https://arxiv.org/) (versiones preprint)
- [Papers With Code](https://paperswithcode.com/) (artículos con implementaciones)

**Nota:** Se recomienda leer estos artículos en orden cronológico para entender la evolución histórica de las redes neuronales.
